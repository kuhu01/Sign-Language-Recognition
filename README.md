# ğŸ–ï¸ Sign Language Recognition System

This project implements a real-time sign language recognition system using a custom hand gesture dataset. The model was trained using [Google Teachable Machine](https://teachablemachine.withgoogle.com/) and integrated into a Python-based application for testing and live predictions.

## ğŸ“ Project Structure

- `data_collection.py`: Script for collecting custom hand gesture data via webcam.
- `sign_language_test.py`: Test file to run real-time predictions using the trained model.
- `model/`: Folder containing the trained Teachable Machine model (downloaded `.keras`).
- `README.md`: This documentation.

## ğŸš€ Features

- Collects your own dataset using webcam for custom sign gestures.
- Real-time sign language recognition using the webcam.
- Simple and lightweight design with browser-trained model support.

## ğŸ› ï¸ Technologies Used

- Python
- OpenCV
- Teachable Machine (Image Model)
- NumPy

## Dataset
Hand gesture images collected manually using webcam.

Trained using Google's Teachable Machine (Image Classification model).
